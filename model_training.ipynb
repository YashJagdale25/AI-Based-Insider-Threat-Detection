{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('/content/drive/MyDrive/DESIGN PROJECT/final_feature_vector.csv')\n",
    "\n",
    "# Encode categorical columns\n",
    "user_encoder = LabelEncoder()\n",
    "df['user_id_encoded'] = user_encoder.fit_transform(df['user'])\n",
    "\n",
    "# Extract target variable\n",
    "y_true = df.pop('is_anomaly')\n",
    "\n",
    "# Define feature columns\n",
    "features = [\n",
    "    'total_working_seconds', 'total_logon_own_pc', 'total_logon_other_pc',\n",
    "    'total_logon_own_pc_normal', 'total_logon_own_pc_off',\n",
    "    'total_logon_other_pc_normal', 'total_logon_other_pc_off',\n",
    "    'total_emails_sent', 'after_hour_emails', 'total_internal_recipients',\n",
    "    'total_external_recipients', 'total_bcc_recipients', 'mails_with_attachments',\n",
    "    'documents_copy_own_pc', 'documents_copy_other_pc', 'program_files_copy_own_pc',\n",
    "    'program_files_copy_other_pc', 'documents_copy_own_pc_off_hour',\n",
    "    'documents_copy_other_pc_off_hour', 'program_files_copy_own_pc_off_hour',\n",
    "    'program_files_copy_other_pc_off_hour', 'device_connects_on_own_pc_normal_hour',\n",
    "    'device_connects_on_other_pc_normal_hour', 'device_connects_on_own_pc_off_hour',\n",
    "    'device_connects_on_other_pc_off_hour'\n",
    "]\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=7):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Prepare Training Data (Only Normal Data)\n",
    "X_train = create_sequences(df.loc[y_true == 0, features].values, seq_length=7)\n",
    "\n",
    "# Prepare Test Data (All Data)\n",
    "X_test = create_sequences(df[features].values, seq_length=7)\n",
    "y_test = y_true.iloc[len(y_true) - len(X_test):].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized LSTM Autoencoder Model\n",
    "input_layer = Input(shape=(7, len(features)))\n",
    "encoded = LSTM(512, activation='relu', return_sequences=True)(input_layer)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "encoded = LSTM(256, activation='relu', return_sequences=True)(encoded)\n",
    "encoded = Dropout(0.3)(encoded)\n",
    "encoded = LSTM(128, activation='relu', return_sequences=True)(encoded)\n",
    "encoded = Dropout(0.3)(encoded)\n",
    "encoded = LSTM(64, activation='relu', return_sequences=False)(encoded)\n",
    "\n",
    "decoded = RepeatVector(7)(encoded)\n",
    "decoded = LSTM(64, activation='relu', return_sequences=True)(decoded)\n",
    "decoded = LSTM(128, activation='relu', return_sequences=True)(decoded)\n",
    "decoded = LSTM(256, activation='relu', return_sequences=True)(decoded)\n",
    "decoded = LSTM(512, activation='relu', return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(len(features)))(decoded)\n",
    "\n",
    "# Compile Model with Lower Learning Rate\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping with Patience\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train Model\n",
    "history = autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Reconstruction Errors\n",
    "X_pred = autoencoder.predict(X_test)\n",
    "errors = np.mean(np.abs(X_test - X_pred), axis=(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Threshold Using Percentile Method\n",
    "percentile_threshold = 90 # Adjust as needed (higher means fewer false positives)\n",
    "theta = np.percentile(errors, percentile_threshold)\n",
    "y_pred = (errors > theta).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "# Compute ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, errors)\n",
    "\n",
    "# Compute Precision-Recall AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, errors)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"ðŸ“Š Percentile-Based Threshold Evaluation:\")\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC Score: {pr_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, errors)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, marker='.', label=f'ROC-AUC: {roc_auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # Random guess line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Normal\", \"Anomaly\"], yticklabels=[\"Normal\", \"Anomaly\"])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
